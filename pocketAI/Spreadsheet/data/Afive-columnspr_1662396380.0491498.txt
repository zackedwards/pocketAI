GPT3 error: This model's maximum context length is 4097 tokens, however you requested 10036 tokens (36 in your prompt; 10000 for the completion). Please reduce your prompt; or completion length.